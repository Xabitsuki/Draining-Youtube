from multiprocessing import Manager, Process
from functions import *

## Aux functions for iter0 and sfm_pipe
MATCH_GEN_FILES = ['geometric_matches',
                   'GeometricAdjacencyMatrix.svg',
                   'matches.f.txt',
                   'matches.putative.bin',
                   'putative_matches',
                   'PutativeAdjacencyMatrix.svg']


def get_plylst_id(path_vid):

    split = path_vid.split(sep=pth_vids())[1].split('/')
    if len(split) == 3:

        plylst = split[1]
        id_ = split[2]

        return id_, plylst

    elif len(split) == 2:

        id_ = split[1]
        return id_, ''


def make_sets(v_id, plylst=''):
    """Used after the iter_0 function ran to separate the frames into sets.
    Return the path the to the sets folder"""

    triangles = split_triangles(bin_matches_to_adja_mat(path_mtchs=pth_iter0_mtchs(v_id, plylst),
                                                        path_frames=pth_frms(v_id, plylst)))

    return move_triangles(triangles=triangles,
                          path_vid=pth_vid(v_id, plylst),
                          path_frames=pth_frms(v_id, plylst),
                          path_feats=pth_iter0_feats(v_id, plylst))


## iter0 and sfm_pipe


def iter0(path_vid, rate, frame_force=False, feature_force=False, match_force=False, sample=False):
    """Make the first iteration of processing loop: list, compute features and matches
     to split the frames in frame sets.
    Return: path to sets folder and width"""
    v_id, plylst = get_plylst_id(path_vid)

    # Extract frames
    path_frames = pth_frms(v_id, plylst)
    if frame_force:
        remove(path_frames)
    if not os.path.isdir(path_frames):
        xtrct_frame(v_id, plylst, sample, rate)

    # Make iter0 dir
    pth_it0 = pth_iter0(v_id, plylst)
    make_dir(pth_it0)

    # Listing
    width = get_dic_info(path_vid)['width']
    cmd = "openMVG_main_SfMInit_ImageListing -i {} -o {} -f {}".format(path_frames, pth_it0, width)
    os.system(command=cmd)

    # Compute features
    path_feat = pth_iter0_feats(v_id, plylst)
    if feature_force:
        remove(path_feat)
    if not os.path.isdir(path_feat):
        make_dir(path_feat)
        path_sfm = os.path.join(pth_it0, 'sfm_data.json')
        cmd = 'openMVG_main_ComputeFeatures -i {} -o {}'.format(path_sfm, path_feat)
        os.system(cmd)

    # Compute  matches
    if match_force:
        for file in MATCH_GEN_FILES:
            pth_file = os.path.join(path_feat, file)
            remove(pth_file)
    if not os.path.isfile(pth_iter0_mtchs(v_id, plylst)):
        path_sfm = os.path.join(pth_it0, 'sfm_data.json')
        cmd = 'openMVG_main_ComputeMatches -i {} -o {}'.format(path_sfm, path_feat)
        os.system(cmd)

    # Make sets
    path_sets = pth_sets(v_id, plylst)
    if feature_force and match_force:
        remove(path_sets)
    if not os.path.isdir(path_sets):
        path_sets = make_sets(v_id, plylst)

    remove_ds_store(path_sets)
    return path_sets, width


def sfm_pipe(pth_set, width):
    """Function that performs the sfm pipeline given the path to
    a set as generated by make_sets."""
    frames = os.path.join(pth_set, 'frames')
    features = os.path.join(pth_set, 'features')
    openmvg_list(width=width, pth_frms=frames, pth_out=pth_set)

    path_sfm = pth_sfm(pth_set)
    openmvg_features(pth_sfm=path_sfm, pth_features=features)
    openmvg_matches(pth_sfm=path_sfm, pth_matches=features)

    path_incr = os.path.join(pth_set, 'incremental')
    make_dir(path_incr)

    openmvg_incremental(pth_sfm=path_sfm, pth_matches=features, pth_incr=path_incr)
    openmvg_colors(pth_incr=path_incr)


## Aux functions for parallelisation


def launch_batch_par(target, args_l):
    """ Launch processes in parallel for specified target and list of arguments"""
    for args in args_l:
        Process(target=target, args=args).start()


def list_extract(lst, max_num):
    """ Function used to pop a number of elements from a list equal or less than max_num """

    ret_lst = []
    if len(lst) >= max_num:
        for i in range(max_num):
            ret_lst.append(lst.pop())

    else:  # less elements than max_num
        for i in reversed(range(len(lst))):
            ret_lst.append(lst.pop())

    return ret_lst


## Many videos sequentially


def drain_many_seq(vids_list=[], plylst ='', rate=1, cpu_nbr=8, frame_force=False, feature_force=False, match_force=False, sample=False):
    """Process many videos in parallel.
    iter0 are executed in parallel.
    sfm_pipe are executed for each video in parallel but each set for each video is treated sequentially.
    Use : pass either a list of vid ids or the name of a playlist"""

    manager = Manager()
    shared_list = manager.list()
    # if playlist, generate vid list from playlist
    if plylst:
        for el in os.listdir(pth_plylst(plylst)):
            vids_list.append(el)

    # iter0s step
    target = iter0_seq
    while not len(vids_list) == 0:
        args_l=[]
        v_ids = list_extract(lst=vids_list, max_num=cpu_nbr)
        args_l = [((pth_vid(v_id=v_id, plylst=plylst),rate, frame_force, feature_force, match_force, sample), shared_list)
                  for v_id in v_ids]

        control_launch = Process(target=launch_batch_par, args=(target, args_l))
        control_launch.start()
        control_launch.join()

    # sfm_pipes step
    target = sfm_pipe_seq
    while not len(shared_list) == 0:

        args_l = list_extract(lst=shared_list, max_num=cpu_nbr)

        control_launch = Process(target=launch_batch_par, args=(target, args_l))
        control_launch.start()
        control_launch.join()


def iter0_seq(args_iter0, shared_list):
    """Calls iter0 and append the returns to the shared_list"""

    paths_sets, width = iter0(*args_iter0)
    shared_list.append((paths_sets, width))


def sfm_pipe_seq(pth_sets, width):
    """ Executes sfm_pipe squentially for each set."""
    pth_sets = [os.path.join(pth_sets, el) for el in os.listdir(pth_sets)]

    for pth_set in pth_sets:
        args = (pth_set, width)
        single_execution = Process(target=sfm_pipe, args=args)
        single_execution.start()
        single_execution.join()


## Single video in parallel


def drain_one(url, dl_format=248, rate=2, cpu_number=8, frame_force=False, feature_force=False, match_force=False, sample=False):
    """Function to download and process one video."""

    yt_dl(url=url, format=dl_format)
    path_vid = pth_vid(url_to_id(url))

    path_sets, width = iter0(path_vid=path_vid, rate = rate,
                             frame_force=frame_force, feature_force=feature_force, match_force=match_force,
                             sample=sample)

    sfm_pipe_par(pth_sets=path_sets, width=width, cpu_number=cpu_number)


def sfm_pipe_par(pth_sets, width, cpu_number=8):
    """ Executes sfm_pipe in parallel.
    At max a number of process equal to cpu_number."""

    pth_sets = [os.path.join(pth_sets, el) for el in os.listdir(pth_sets)]

    target = sfm_pipe
    while not len(pth_sets) == 0:

        pths = list_extract(lst=pth_sets, max_num=cpu_number)
        args_l = [(pth, width) for pth in pths]

        batch_execution = Process(target=launch_batch_par, args=(target, args_l))
        batch_execution.start()
        batch_execution.join()


## Many videos in a fully parallel manner


def drain_many_par(plylsts=[], vids=[], rate=2, frame_force=False, feature_force=False, match_force=False, sample=False):
    """Launch parent processes.
    Execution finishes when all iter0 and subordinary sfm_pipes jobs terminated."""

    # One parent process: all other processes are children
    parent_process = Process(target=launch_all_par, args=(plylsts, vids, rate, frame_force, feature_force, match_force, sample))
    parent_process.start()
    parent_process.join()


def launch_all_par(plylsts=[], vids=[], rate=2, frame_force=False, feature_force=False, match_force=False, sample=False):
    """Spawns as many iter0 as the number of videos in playlists or in the videos list.
    After an iter0 process finishes, it launches the sfm_pipes in parallel."""

    for plylst in plylsts:
        for v_id in os.listdir(pth_plylst(plylst)):
            args = (pth_vid(v_id, plylst), rate, frame_force, feature_force, match_force, sample)
            Process(target=iter0_sfm_par, args=args).start()

    for v_id in vids:
        args = (pth_vid(v_id), rate, frame_force, feature_force, match_force, sample)
        Process(target=iter0_sfm_par, args=(args,)).start()


def iter0_sfm_par(args):
    """Performs iter0() and launch sfm_pipe processes with
    the generated sets."""

    path_set_dir, width = iter0(*args)
    pth_sets = [os.path.join(path_set_dir, el) for el in os.listdir(path_set_dir)]

    # start new process
    for pth_set in pth_sets:
        args = (pth_set, width)
        Process(target=sfm_pipe, args=args).start()

