from multiprocessing import Manager, Process
from functions import *

MATCH_GEN_FILES = ['geometric_matches',
                   'GeometricAdjacencyMatrix.svg',
                   'matches.f.txt',
                   'matches.putative.bin',
                   'putative_matches',
                   'PutativeAdjacencyMatrix.svg']

####################################### sets functions


def make_sets(v_id, plylst=''):
    """Used after the iter_0 function ran to separate the frames into sets.
    Return the path the to the sets folder"""

    triangles = split_triangles(bin_matches_to_adja_mat(path_mtchs=pth_iter0_mtchs(v_id, plylst),
                                                        path_frames=pth_frms(v_id, plylst)))

    return move_triangles(triangles=triangles,
                          path_vid=pth_vid(v_id, plylst),
                          path_frames=pth_frms(v_id, plylst),
                          path_feats=pth_iter0_feats(v_id, plylst))


def sort_sets(path_vid):
    """Puts sets where the incremental failed in folder Fails"""

    v_id, plylst = get_plylst_id(path_vid)

    sets = pth_sets(v_id, plylst)

    fails_p = os.path.join(sets, 'fails')
    make_dir(fails_p)

    for set in os.listdir(sets):
        set_p = os.path.join(sets, set) # move fails in fail folder
        if os.path.isdir(os.path.join(set_p, 'incremental_fail')):
            os.renames(old=set_p, new=os.path.join(fails_p, set))


#######################################  iter0 and sfm_pipe


def iter0(v_id, plylst='', rate=2, sample=False, frame_force=False, feature_force=False, match_force=False, video_mode=5):
    """Make the first iteration of processing loop: list, compute features and matches
       to split the frames in frame sets.
       Return: path to sets folder and width"""

    # Extract frames
    path_frames = pth_frms(v_id, plylst)
    if frame_force:
        remove(path_frames)
    if not os.path.isdir(path_frames):
        xtrct_frame(v_id, plylst, sample, rate)

    # Make iter0 dir
    pth_it0 = pth_iter0(v_id, plylst)
    make_dir(pth_it0)

    # Listing
    width = get_dic_info(v_id, plylst)['width']
    openmvg_list(width, path_frames, pth_it0)

    path_feat = pth_iter0_feats(v_id, plylst)
    path_sfm = os.path.join(pth_it0, 'sfm_data.json')

    # Compute features
    if feature_force or not os.path.isdir(path_feat):
        openmvg_features(path_sfm, path_feat, force=feature_force)

    # Compute  matches
    if match_force or not os.path.isfile(pth_iter0_mtchs(v_id, plylst)):
        openmvg_matches(path_sfm, path_feat, video_mode=video_mode, force=match_force)

    # Make sets
    path_sets = pth_sets(v_id, plylst)
    if not os.path.isdir(path_sets) or feature_force and match_force:
        path_sets = make_sets(v_id, plylst)
        remove_ds_store(path_sets)

    return path_sets, width


def sfm_pipe(pth_set, width, video_mode=10):
    """Function that performs the sfm pipeline given the path to
       a set as generated by make_sets."""

    frames = os.path.join(pth_set, 'frames')
    features = os.path.join(pth_set, 'features')
    openmvg_list(width=width, pth_frms=frames, pth_out=pth_set)

    path_sfm = pth_sfm(pth_set)
    openmvg_features(pth_sfm=path_sfm, pth_features=features)
    openmvg_matches(pth_sfm=path_sfm, pth_matches=features,
                    video_mode=video_mode)

    path_incr = os.path.join(pth_set, 'incremental')
    make_dir(path_incr)

    openmvg_incremental(pth_sfm=path_sfm, pth_matches=features, pth_incr=path_incr)
    openmvg_colors(pth_incr=path_incr)


####################################### Aux functions for parallelisation


def launch_batch_par(target, args_l):
    """ Launch processes in parallel for specified target and list of arguments"""
    for args in args_l:
        Process(target=target, args=args).start()


def list_extract(lst, max_num):
    """ Function used to pop a number of elements from a list equal or less than max_num """

    ret_lst = []
    if len(lst) >= max_num:
        for i in range(max_num):
            ret_lst.append(lst.pop())

    else:  # less elements than max_num
        for i in reversed(range(len(lst))):
            ret_lst.append(lst.pop())

    return ret_lst


####################################### Many videos sequentially


def drain_many_seq(vids_list=[], plylst ='', rate=1, cpu_nbr=8,
                   sample=False, frame_force=False,
                   feature_force=False,
                   match_force=False, video_mode=5):
    """Process many videos in parallel.
       iter0 are executed in parallel.
       sfm_pipe are executed for each video in parallel but each set for each video is treated sequentially.
       Use : pass either a list of vid ids or the name of a playlist"""

    manager = Manager()
    shared_list = manager.list()
    # if playlist, generate vid list from playlist
    if plylst:
        for el in os.listdir(pth_plylst(plylst)):
            vids_list.append(el)

    # iter0s step
    target = iter0_seq
    while not len(vids_list) == 0:
        v_ids = list_extract(lst=vids_list, max_num=cpu_nbr)
        args_l = [((v_id, plylst, rate,  sample, frame_force, feature_force, match_force, video_mode), shared_list)
                  for v_id in v_ids]

        control_launch = Process(target=launch_batch_par, args=(target, args_l))
        control_launch.start()
        control_launch.join()

    # sfm_pipes step
    target = sfm_pipe_seq
    while not len(shared_list) == 0:

        args_l = list_extract(lst=shared_list, max_num=cpu_nbr)

        control_launch = Process(target=launch_batch_par, args=(target, args_l))
        control_launch.start()
        control_launch.join()


def iter0_seq(args_iter0, shared_list):
    """Calls iter0 and append the returns to the shared_list"""
    paths_sets, width = iter0(*args_iter0)
    shared_list.append((paths_sets, width))


def sfm_pipe_seq(pth_sets, width):
    """ Executes sfm_pipe sequentially for each set."""
    path_sets = [os.path.join(pth_sets, el) for el in os.listdir(pth_sets)]

    for path_set in path_sets:
        args = (path_set, width)
        single_execution = Process(target=sfm_pipe, args=args)
        single_execution.start()
        single_execution.join()


#######################################  Single video in parallel


def drain_one(url, playlist='', dl_format=248, rate=2, cpu_number=8,
              sample=False, frame_force=False,
              feature_force=False,
              match_force=False, video_mode=10):
    """Function to download and process one video.
       Return path to video folder. """

    v_id, plylst = yt_dl(url=url, playlist=playlist,format=dl_format)
    path_vid = pth_vid(v_id, plylst)

    path_sets, width = iter0(v_id=v_id, plylst=plylst,
                             rate=rate,
                             sample=sample, frame_force=frame_force,
                             feature_force=feature_force,
                             match_force=match_force, video_mode=video_mode)

    sfm_pipe_par(pth_sets=path_sets, width=width, cpu_number=cpu_number)
    return path_vid

def sfm_pipe_par(pth_sets, width, cpu_number=8):
    """Executes sfm_pipe in parallel.
       At max a number of process equal to cpu_number."""

    pth_sets = [os.path.join(pth_sets, el) for el in os.listdir(pth_sets)]

    target = sfm_pipe
    while not len(pth_sets) == 0:

        pths = list_extract(lst=pth_sets, max_num=cpu_number)
        args_l = [(pth, width) for pth in pths]

        batch_execution = Process(target=launch_batch_par, args=(target, args_l))
        batch_execution.start()
        batch_execution.join()


#######################################  Many videos in a fully parallel manner


def drain_many_par(plylsts=[], vids=[], rate=2, sample=False, frame_force=False, feature_force=False, match_force=False):
    """Launch parent processes.
       Execution finishes when all iter0 and subordinary sfm_pipes jobs terminated."""

    # One parent process: all other processes are children
    parent_process = Process(target=launch_all_par, args=(plylsts, vids, rate, sample, frame_force, feature_force, match_force))
    parent_process.start()
    parent_process.join()


def launch_all_par(plylsts=[], vids=[], rate=2, sample=False, frame_force=False, feature_force=False, match_force=False):
    """Spawns as many iter0 as the number of videos in playlists or in the videos list.
       After an iter0 process finishes, it launches the sfm_pipes in parallel."""

    for plylst in plylsts:
        for v_id in os.listdir(pth_plylst(plylst)):
            args = (pth_vid(v_id, plylst), rate, sample, frame_force, feature_force, match_force)
            Process(target=iter0_sfm_par, args=args).start()

    for v_id in vids:
        args = (pth_vid(v_id), rate, sample, frame_force, feature_force, match_force)
        Process(target=iter0_sfm_par, args=(args,)).start()


def iter0_sfm_par(args):
    """Performs iter0() and launch sfm_pipe processes with
       the generated sets."""

    path_set_dir, width = iter0(*args)
    pth_sets = [os.path.join(path_set_dir, el) for el in os.listdir(path_set_dir)]

    # start new process
    for pth_set in pth_sets:
        args = (pth_set, width)
        Process(target=sfm_pipe, args=args).start()

